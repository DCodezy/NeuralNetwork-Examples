{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomOut implementation for MXNet\n",
    "This notebook is a demo of the RandomOut algorithm. It is implemented as a Monitor that can be passed to the fit method of FeedForward model object. Every epoch the monitor will be invoked and test that every convolutional filter has a CGN value greater than the tau value passed in. If a filter fails the check then it is reinitialized using the initializer from the model.\n",
    "\n",
    "The code is set up to train the 28x28 inception arch on the CIFAR-10 dataset. It can be run on multiple GPUs by setting the num_devs variable.\n",
    "\n",
    "Using the default parameters here after 20 epochs we achieve the following testing accuracy:\n",
    "+ wo/RandomOut = 0.7075\n",
    "+ w/RandomOut = 0.7929\n",
    "\n",
    "Paper: https://arxiv.org/abs/1602.05931\n",
    "\n",
    "ShortScience.org: http://www.shortscience.org/paper?bibtexKey=journals/corr/CohenL016\n",
    "\n",
    "This nodebook can be run from the command line using: \n",
    "\n",
    "    jupyter nbconvert randomout-cifar-inception.ipynb --to script\n",
    "    python randomout-cifar-inception.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cmath\n",
    "import graphviz\n",
    "import argparse\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=1)\n",
    "parser.add_argument('--epochs', type=int, default=4)\n",
    "parser.add_argument('--batch-size', type=int, default=128)\n",
    "parser.add_argument('--tau', type=float, default=1e-30)\n",
    "parser.add_argument('--randomout', type=str, default=\"True\")\n",
    "parser.add_argument('--network', type=str, default=\"inception-28-small\")\n",
    "parser.add_argument('-f', type=str, default='')\n",
    "args = parser.parse_args()\n",
    "args.f = ''\n",
    "\n",
    "# setup logging\n",
    "import logging\n",
    "logging.getLogger().handlers = []\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "#logging.root = logging.getLogger(str(args))\n",
    "logging.root = logging.getLogger()\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "softmax = importlib.import_module('symbol_' + args.network).get_symbol(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you'd like to see the network structure, run the plot_network function\n",
    "a = mx.viz.plot_network(symbol=softmax.get_internals(),node_attrs={'shape':'rect','fixedsize':'false'},\n",
    "                       shape={\"data\":(1,3, 28, 28)}) \n",
    "\n",
    "a.body.extend(['rankdir=RL', 'size=\"40,5\"'])\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mx.random.seed(args.seed)\n",
    "num_epoch = args.epochs\n",
    "batch_size = args.batch_size\n",
    "num_devs = 1\n",
    "model = mx.model.FeedForward(ctx=[mx.gpu(i) for i in range(num_devs)], symbol=softmax, num_epoch = num_epoch,\n",
    "                             learning_rate=0.1, momentum=0.9, wd=0.00001\n",
    "                             ,optimizer=mx.optimizer.Adam()\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import get_data\n",
    "get_data.GetCifar10()\n",
    "\n",
    "train_dataiter = mx.io.ImageRecordIter(\n",
    "        shuffle=True,\n",
    "        path_imgrec=\"data/cifar/train.rec\",\n",
    "        mean_img=\"data/cifar/cifar_mean.bin\",\n",
    "        rand_crop=False,\n",
    "        rand_mirror=False,\n",
    "        data_shape=(3,28,28),\n",
    "        batch_size=batch_size,\n",
    "        preprocess_threads=4)\n",
    "# test iterator make batch of 128 image, and center crop each image into 3x28x28 from original 3x32x32\n",
    "# Note: We don't need round batch in test because we only test once at one time\n",
    "test_dataiter = mx.io.ImageRecordIter(\n",
    "        path_imgrec=\"data/cifar/test.rec\",\n",
    "        mean_img=\"data/cifar/cifar_mean.bin\",\n",
    "        rand_crop=False,\n",
    "        rand_mirror=False,\n",
    "        data_shape=(3,28,28),\n",
    "        batch_size=batch_size,\n",
    "        round_batch=False,\n",
    "        preprocess_threads=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mxnet.ndarray import NDArray\n",
    "from mxnet.base import NDArrayHandle\n",
    "from mxnet import ndarray\n",
    "\n",
    "class RandomOutMonitor(mx.monitor.Monitor):\n",
    "    \n",
    "    def __init__(self, initializer, network, tau=0.000001, *args,**kwargs):\n",
    "        mx.monitor.Monitor.__init__(self, 1, *args, **kwargs) \n",
    "        self.tau = tau\n",
    "        self.initializer = initializer\n",
    "        \n",
    "        # here the layers we want to subject to the threshold are specified\n",
    "        targetlayers = [x for x in network.list_arguments() if x.startswith(\"conv\") and x.endswith(\"weight\")]\n",
    "        self.targetlayers = targetlayers\n",
    "        \n",
    "        logging.info(\"RandomOut active on layers: %s\" % self.targetlayers)\n",
    "        \n",
    "    def toc(self):\n",
    "        for exe in self.exes:\n",
    "            for array in exe.arg_arrays:\n",
    "                array.wait_to_read()\n",
    "        for exe in self.exes:\n",
    "            for name, array in zip(exe._symbol.list_arguments(), exe.arg_arrays):\n",
    "                self.queue.append((self.step, name, self.stat_func(array)))\n",
    "                \n",
    "        for exe in self.exes:\n",
    "            weights = dict(zip(softmax.list_arguments(), exe.arg_arrays))\n",
    "            grads = dict(zip(softmax.list_arguments(), exe.grad_arrays))\n",
    "            numFilters = 0\n",
    "            for name in self.targetlayers:\n",
    "            \n",
    "                filtersg = grads[name].asnumpy()\n",
    "                filtersw = weights[name].asnumpy()\n",
    "\n",
    "                #get random array to copy over\n",
    "                filtersw_rand = mx.nd.array(filtersw.copy())\n",
    "                self.initializer(name, filtersw_rand)\n",
    "                filtersw_rand = filtersw_rand.asnumpy()\n",
    "                \n",
    "                agrads = [0.0] * len(filtersg)\n",
    "                for i in range(len(filtersg)):\n",
    "                    agrads[i] = np.absolute(filtersg[i]).sum()\n",
    "                    if agrads[i] < self.tau:\n",
    "                        numFilters = numFilters+1\n",
    "                        #logging.info(\"RandomOut: filter %i of %s has been randomized because CGN=%f\" % (i,name,agrads[i]))\n",
    "                        filtersw[i] = filtersw_rand[i]\n",
    "\n",
    "                #logging.info(\"%s, %s, %s\" % (name, min(agrads),np.mean(agrads)))\n",
    "            \n",
    "                weights[name] = mx.nd.array(filtersw)\n",
    "                #print filtersw\n",
    "            if numFilters >0:\n",
    "                #logging.info(\"numFilters replaced: %i\"%numFilters)   \n",
    "                exe.copy_params_from(arg_params=weights)\n",
    "            \n",
    "        self.activated = False\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RandomOut active on layers: ['convolution0_weight', 'convolution1_weight', 'convolution2_weight', 'convolution3_weight', 'convolution4_weight', 'convolution5_weight', 'convolution6_weight', 'convolution7_weight', 'convolution8_weight', 'convolution9_weight', 'convolution10_weight', 'convolution11_weight', 'convolution12_weight', 'convolution13_weight', 'convolution14_weight', 'convolution15_weight', 'convolution16_weight', 'convolution17_weight', 'convolution18_weight']\n",
      "INFO:root:Start training with [gpu(0)]\n",
      "/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/ndarray.py:422: RuntimeWarning: copy an array to itself, is it intended?\n",
      "  RuntimeWarning)\n",
      "INFO:root:Epoch[0] Batch [50]\tSpeed: 137.94 samples/sec\tTrain-accuracy=0.101875\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 135.05 samples/sec\tTrain-accuracy=0.102813\n",
      "INFO:root:Epoch[0] Batch [150]\tSpeed: 134.95 samples/sec\tTrain-accuracy=0.103281\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 134.61 samples/sec\tTrain-accuracy=0.102031\n",
      "INFO:root:Epoch[0] Batch [250]\tSpeed: 134.78 samples/sec\tTrain-accuracy=0.101000\n",
      "INFO:root:Epoch[0] Batch [300]\tSpeed: 134.79 samples/sec\tTrain-accuracy=0.101302\n",
      "INFO:root:Epoch[0] Batch [350]\tSpeed: 134.64 samples/sec\tTrain-accuracy=0.101027\n",
      "INFO:root:Epoch[0] Resetting Data Iterator\n",
      "INFO:root:Epoch[0] Train-accuracy=0.100424\n",
      "INFO:root:Epoch[0] Time cost=371.288\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.099684\n",
      "INFO:root:Epoch[1] Batch [50]\tSpeed: 137.38 samples/sec\tTrain-accuracy=0.097031\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 134.57 samples/sec\tTrain-accuracy=0.095078\n",
      "INFO:root:Epoch[1] Batch [150]\tSpeed: 134.75 samples/sec\tTrain-accuracy=0.096927\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 134.77 samples/sec\tTrain-accuracy=0.096914\n",
      "INFO:root:Epoch[1] Batch [250]\tSpeed: 134.56 samples/sec\tTrain-accuracy=0.096687\n",
      "INFO:root:Epoch[1] Batch [300]\tSpeed: 134.68 samples/sec\tTrain-accuracy=0.098073\n"
     ]
    }
   ],
   "source": [
    "train_dataiter.reset()\n",
    "if args.randomout == \"True\":\n",
    "    model.fit(X=train_dataiter,\n",
    "        eval_data=test_dataiter,\n",
    "        eval_metric=\"accuracy\",\n",
    "        batch_end_callback=mx.callback.Speedometer(batch_size)\n",
    "        ,monitor=RandomOutMonitor(initializer = model.initializer, network=softmax, tau=args.tau)\n",
    "        )\n",
    "else:\n",
    "    model.fit(X=train_dataiter,\n",
    "        eval_data=test_dataiter,\n",
    "        eval_metric=\"accuracy\",\n",
    "        batch_end_callback=mx.callback.Speedometer(batch_size)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
